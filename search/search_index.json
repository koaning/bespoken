{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<pre>\n\n            \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557  \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2557   \u2588\u2588\u2557\n            \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2551 \u2588\u2588\u2554\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2551\n            \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\n            \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u255d  \u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u255d  \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\n            \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551     \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551  \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\n            \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d      \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u2550\u2550\u255d\n\n            Define your agent. Pick your tools. Add your commands. Make it your own.\n        </pre>"},{"location":"#what-is-bespoken","title":"What is Bespoken?","text":"<p>Bespoken is a framework that allows you to create custom LLM agents for the command line. </p> <pre>\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Tools \u2502 +\u2502  LLM  \u2502 +\u2502  UI  \u2502 +\u2502 Cmds  \u2502  =  \u2502    Custom Agent     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    </pre> <p>You're able to pick your favourite LLM and combine it with your own tools and commands. We also offer a simple UI framework to allow for dynamic forms with auto-completion. All of this is wrapped in a single command line utility that covers enough ground to get you started on your own bespoke agent.</p>"},{"location":"#why-build-this","title":"Why build this?","text":"<p>It all started when I was working with claude code and found myself constantly telling it that it was only allow to make changes to a specific file. Similarily, I wanted to be able to make commits from within the chat interface without wasting tokens. It turned into a fun evening and before I knew it I had built myself a flexible framework on top of llm. </p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>If you want to use <code>bespoken</code> you'll want to install it first. </p> <pre><code>uv pip install bespoken\n</code></pre> <p>From here, the easiest way to explain how <code>bespoken</code> works is to show you an example. </p> app.py<pre><code>from bespoken import chat\nfrom bespoken.tools import FileTool, TodoTools\nfrom bespoken import ui\n\ndef set_role():\n    \"\"\"Set a voice for the assistant\"\"\"\n    roles = [\"pirate\", \"teacher\", \"professor\"]\n    role = ui.choice(\"What role should I take?\", roles)\n    return f\"You are now speaking like a {role}. Please respond in character for this role.\"\n\nchat(\n    model_name=\"anthropic/claude-3-5-sonnet-20240620\",\n    tools=[FileTool(\"edit.py\"), TodoTools()],\n    system_prompt=\"You are a helpful assistant.\",\n    debug=False,\n    slash_commands={\n        \"/role\": set_role,\n    }\n)\n</code></pre> <p>You can run this app via <code>uv run app.py</code> and you will get an agent. The agent is basically a while loop that keeps on asking for input and the LLM will call tools when it deems it appropriate. This experience is constrained and bespoke to your needs because you fully control what tools are available to the LLM. Depending on what commands you give the LLM  it will pick up the <code>FileTool</code> or <code>TodoTools</code> to call the tools on your behalf. The <code>FileTool</code> can read/edit a specific file and the <code>TodoTools</code> can keep track of an internal todo list. You're also able to add commands to the agent that you can trigger yourself. In this example we added the <code>/role</code> command that allows you to change the role of the assistant. You'll also notice that we're adding a system prompt that you can also customise. </p>"},{"location":"#how-does-it-work","title":"How does it work?","text":"<p>Bespoken builds on top of the llm tool created by Simon Willison. This gives us ample LLMs to pick from, some of which support \"tools\".</p> <p>Tools are a way to give an LLM the ability to perform actions on your behalf. You can define these as normal Python functions/classes. If you give these good names and docstrings, the LLM can call them when it deems it appropriate and can interpret the output. This library provides you with plenty of tools out of the box, but you can also define your own. The whole point is that you only give the LLM access to the tools it needs to perform its task and nothing more, as a guardrail.</p> <p>Besides tools this library also allows you to customise the system prompt and you can also define \"slash commands\". </p> <p>Slash commands are a way to give an LLM the ability to perform actions on your behalf. Unlike a tool, the LLM does not trigger it, you do! Some of these commands are pre-defined prompts that you like to use while debugging while others might allow you to make a commit manually from within the chat interface (that way you won't waste precious tokens). We ship with some pre-defined commands but the whole point is that you can also configure your own. </p> <p>One of the main features of <code>bespoken</code> is that we also allow you to use <code>bespoken.ui</code> to enhance these tools and commands. </p> <p>When the <code>FileTool</code> is about to make a change to a file, it will confirm if you agree to the change. To make this nice it is calling <code>bespoken.ui.confirm()</code> internally and depending on what the user returns the LLM will branch off to a different state. You can add these UI steps in your tools but also in your slash commands as you see fit. Besides ui, we also offer some shortcuts like <code>@&lt;filename&gt;</code> that all benefit from autocompletion too.</p> <p>We also allow you to change the basics like the system prompt and the base model. Bespoken also comes with debugging tools to figure out what the tools are doing while you interact with the LLM. </p>"},{"location":"#next-steps","title":"Next steps?","text":"<p>This is about the gist of it. The project is in it's early stages right now and we're mainly interested in gathering feedback. We could make it look nicer, add more tools, more prompts or more commands, probably add a good callback system for logging/debugging ... but before doing that we'd like to make sure that our pipeline is flexible enough to cover the needs of a general crowd. So let us know! </p> <p>You can find the source code on github and we'd love to hear from you!</p>"},{"location":"api/prompts/","title":"Prompts API Reference","text":"<p>This page documents the prompts available in <code>bespoken.prompts</code>.</p>"},{"location":"api/prompts/#available-prompts","title":"Available Prompts","text":""},{"location":"api/prompts/#marimo_prompt","title":"marimo_prompt","text":"<p>A specialized prompt for creating data science notebooks using marimo.</p> <pre><code>from bespoken.prompts import marimo_prompt\nfrom bespoken import chat\n\n# Use the marimo prompt for notebook assistance\nchat(\n    model_name=\"anthropic/claude-3-5-sonnet-20240620\",\n    system_prompt=marimo_prompt,\n    tools=[FileTool(\"notebook.py\")]\n)\n</code></pre> <p>Key Features: - Specialized for marimo notebook development - Prefers polars over pandas for data manipulation - Prefers altair over matplotlib for visualization - Understands marimo's cell-based structure with <code>@app.cell</code> decorators - Knows about marimo's reactive programming model - Includes UV script dependencies format</p> <p>Example marimo file structure the prompt understands: <pre><code># /// script\n# requires-python = \"&gt;=3.11\"\n# dependencies = [\n#     \"marimo\",\n#     \"numpy==2.3.1\",\n# ]\n# ///\n\nimport marimo\n\n__generated_with = \"0.14.10\"\napp = marimo.App(width=\"columns\")\n\n@app.cell\ndef _():\n    import marimo as mo\n    import numpy as np\n    return mo, np\n\n@app.cell\ndef _(mo):\n    slider = mo.ui.slider(1, 10, 1)\n    slider\n    return (slider,)\n\nif __name__ == \"__main__\":\n    app.run()\n</code></pre></p>"},{"location":"api/prompts/#using-custom-prompts","title":"Using Custom Prompts","text":"<p>You can create your own system prompts to customize the assistant's behavior:</p> <pre><code>from bespoken import chat\n\n# Define a custom prompt\nmy_prompt = \"\"\"You are an expert Python developer specializing in web applications.\nYou prefer FastAPI for APIs and focus on clean, maintainable code.\nAlways include type hints and proper error handling.\"\"\"\n\n# Use the custom prompt\nchat(\n    model_name=\"anthropic/claude-3-5-sonnet-20240620\",\n    system_prompt=my_prompt,\n    tools=[FileSystem()]\n)\n</code></pre>"},{"location":"api/prompts/#prompt-best-practices","title":"Prompt Best Practices","text":""},{"location":"api/prompts/#1-be-specific-about-preferences","title":"1. Be Specific About Preferences","text":"<pre><code>prompt = \"\"\"You are a data analysis assistant.\nPreferences:\n- Use polars for data manipulation (not pandas)\n- Use plotly for interactive visualizations\n- Always validate data types before operations\n- Include docstrings for all functions\"\"\"\n</code></pre>"},{"location":"api/prompts/#2-include-context-about-the-project","title":"2. Include Context About the Project","text":"<pre><code>prompt = \"\"\"You are helping with a Django web application.\nProject structure:\n- apps/ contains Django apps\n- Use Django 4.2 features\n- Follow the project's existing patterns\n- Tests go in tests/ directory\"\"\"\n</code></pre>"},{"location":"api/prompts/#3-set-behavioral-guidelines","title":"3. Set Behavioral Guidelines","text":"<pre><code>prompt = \"\"\"You are a helpful coding assistant.\nGuidelines:\n- Ask for clarification when requirements are unclear\n- Suggest test cases for new functions\n- Point out potential security issues\n- Explain complex logic with comments\"\"\"\n</code></pre>"},{"location":"api/prompts/#combining-prompts-with-tools","title":"Combining Prompts with Tools","text":"<p>Different prompts work best with different tools:</p> <pre><code># For file editing tasks\nfrom bespoken.prompts import marimo_prompt\nfrom bespoken.tools import FileTool\n\nchat(\n    system_prompt=marimo_prompt,\n    tools=[FileTool(\"analysis.py\")]\n)\n\n# For system administration\nadmin_prompt = \"You are a system administrator assistant...\"\nfrom bespoken.tools.command import GitTool, run_command\n\nchat(\n    system_prompt=admin_prompt,\n    tools=[GitTool(), run_command]\n)\n</code></pre>"},{"location":"api/prompts/#dynamic-prompt-modification","title":"Dynamic Prompt Modification","text":"<p>You can modify prompts during runtime using slash commands:</p> <pre><code>from bespoken import chat, ui\n\ndef change_style():\n    \"\"\"Change the coding style preference\"\"\"\n    styles = [\"functional\", \"object-oriented\", \"procedural\"]\n    style = ui.choice(\"Select coding style:\", styles)\n    return f\"From now on, prefer {style} programming style.\"\n\nchat(\n    system_prompt=\"You are a Python developer.\",\n    slash_commands={\n        \"/style\": change_style\n    }\n)\n</code></pre>"},{"location":"api/prompts/#future-prompts","title":"Future Prompts","text":"<p>The prompts module is designed to be extensible. Future additions may include:</p> <ul> <li><code>web_developer_prompt</code> - For web development tasks</li> <li><code>devops_prompt</code> - For DevOps and infrastructure</li> <li><code>api_designer_prompt</code> - For API design and documentation</li> <li><code>test_writer_prompt</code> - For writing comprehensive tests</li> </ul> <p>To request new prompts or contribute your own, please visit the GitHub repository.</p>"},{"location":"api/slash-commands/","title":"Slash Commands API Reference","text":"<p>This page documents how to create and use slash commands in bespoken.</p>"},{"location":"api/slash-commands/#what-are-slash-commands","title":"What are Slash Commands?","text":"<p>Slash commands are user-triggered actions that start with <code>/</code>. Unlike tools (which the LLM calls), slash commands are executed directly by the user during a chat session.</p>"},{"location":"api/slash-commands/#basic-usage","title":"Basic Usage","text":"<pre><code>from bespoken import chat, ui\n\ndef hello_command():\n    \"\"\"Say hello to the user\"\"\"\n    return \"Hello! How can I help you today?\"\n\ndef clear_screen():\n    \"\"\"Clear the terminal screen\"\"\"\n    import os\n    os.system('clear' if os.name == 'posix' else 'cls')\n    return \"Screen cleared!\"\n\nchat(\n    model_name=\"anthropic/claude-3-5-sonnet-20240620\",\n    slash_commands={\n        \"/hello\": hello_command,\n        \"/clear\": clear_screen,\n    }\n)\n</code></pre>"},{"location":"api/slash-commands/#commands-with-user-input","title":"Commands with User Input","text":"<p>Slash commands can interact with the user through UI components:</p> <pre><code>from bespoken import chat, ui\n\ndef set_role():\n    \"\"\"Set a voice for the assistant\"\"\"\n    roles = [\"pirate\", \"teacher\", \"professor\", \"casual\", \"formal\"]\n    role = ui.choice(\"What role should I take?\", roles)\n    return f\"You are now speaking like a {role}. Please respond in character for this role.\"\n\ndef set_temperature():\n    \"\"\"Adjust response creativity\"\"\"\n    temp = ui.input(\"Enter temperature (0.0-1.0): \")\n    try:\n        temp_float = float(temp)\n        if 0 &lt;= temp_float &lt;= 1:\n            return f\"Temperature set to {temp_float}. My responses will be {'more creative' if temp_float &gt; 0.7 else 'more focused'}.\"\n        else:\n            return \"Temperature must be between 0.0 and 1.0\"\n    except ValueError:\n        return \"Invalid temperature value\"\n\nchat(\n    slash_commands={\n        \"/role\": set_role,\n        \"/temp\": set_temperature,\n    }\n)\n</code></pre>"},{"location":"api/slash-commands/#file-operations-commands","title":"File Operations Commands","text":"<pre><code>from bespoken import chat, ui\nfrom pathlib import Path\n\ndef save_conversation():\n    \"\"\"Save the conversation to a file\"\"\"\n    filename = ui.input(\"Enter filename (without extension): \")\n    # In a real implementation, you'd access conversation history\n    Path(f\"{filename}.txt\").write_text(\"Conversation saved!\")\n    return f\"Conversation saved to {filename}.txt\"\n\ndef load_context():\n    \"\"\"Load a file as context\"\"\"\n    filepath = ui.input(\"Enter file path: \")\n    try:\n        content = Path(filepath).read_text()\n        return f\"Loaded {len(content)} characters from {filepath}. I'll keep this in mind.\"\n    except Exception as e:\n        return f\"Error loading file: {e}\"\n\nchat(\n    slash_commands={\n        \"/save\": save_conversation,\n        \"/load\": load_context,\n    }\n)\n</code></pre>"},{"location":"api/slash-commands/#git-integration-commands","title":"Git Integration Commands","text":"<pre><code>from bespoken import chat, ui\nimport subprocess\n\ndef git_status():\n    \"\"\"Show git status\"\"\"\n    result = subprocess.run([\"git\", \"status\"], capture_output=True, text=True)\n    return f\"Git status:\\n{result.stdout}\"\n\ndef git_commit():\n    \"\"\"Make a git commit\"\"\"\n    message = ui.input(\"Enter commit message: \")\n\n    # Stage all changes\n    subprocess.run([\"git\", \"add\", \".\"])\n\n    # Commit\n    result = subprocess.run(\n        [\"git\", \"commit\", \"-m\", message], \n        capture_output=True, \n        text=True\n    )\n\n    if result.returncode == 0:\n        return f\"Successfully committed: {message}\"\n    else:\n        return f\"Commit failed: {result.stderr}\"\n\nchat(\n    slash_commands={\n        \"/status\": git_status,\n        \"/commit\": git_commit,\n    }\n)\n</code></pre>"},{"location":"api/slash-commands/#advanced-command-patterns","title":"Advanced Command Patterns","text":""},{"location":"api/slash-commands/#commands-with-multiple-steps","title":"Commands with Multiple Steps","text":"<pre><code>def configure_project():\n    \"\"\"Interactive project configuration\"\"\"\n    # Step 1: Project type\n    project_type = ui.choice(\n        \"What type of project?\", \n        [\"Web App\", \"CLI Tool\", \"Library\", \"Data Science\"]\n    )\n\n    # Step 2: Language\n    language = ui.choice(\n        \"Primary language?\",\n        [\"Python\", \"JavaScript\", \"TypeScript\", \"Go\"]\n    )\n\n    # Step 3: Confirmation\n    if ui.confirm(f\"Configure as {language} {project_type}?\"):\n        return f\"\"\"Project configured!\nType: {project_type}\nLanguage: {language}\n\nI'll now assist you with {language} best practices for {project_type} development.\"\"\"\n    else:\n        return \"Configuration cancelled.\"\n</code></pre>"},{"location":"api/slash-commands/#commands-that-modify-behavior","title":"Commands that Modify Behavior","text":"<pre><code>def toggle_verbose():\n    \"\"\"Toggle verbose mode\"\"\"\n    # This would typically modify a global state\n    import bespoken.config\n    bespoken.config.DEBUG_MODE = not bespoken.config.DEBUG_MODE\n    status = \"on\" if bespoken.config.DEBUG_MODE else \"off\"\n    return f\"Verbose mode is now {status}\"\n\ndef set_model():\n    \"\"\"Change the LLM model\"\"\"\n    models = [\n        \"anthropic/claude-3-5-sonnet-20240620\",\n        \"openai/gpt-4\",\n        \"anthropic/claude-3-opus-20240229\"\n    ]\n    model = ui.choice(\"Select model:\", models)\n    # In practice, this would update the chat configuration\n    return f\"Model changed to {model} (will take effect in next session)\"\n</code></pre>"},{"location":"api/slash-commands/#commands-with-error-handling","title":"Commands with Error Handling","text":"<pre><code>def run_tests():\n    \"\"\"Run project tests\"\"\"\n    test_framework = ui.choice(\n        \"Test framework?\",\n        [\"pytest\", \"unittest\", \"jest\", \"go test\"]\n    )\n\n    try:\n        if test_framework == \"pytest\":\n            result = subprocess.run(\n                [\"pytest\", \"-v\"], \n                capture_output=True, \n                text=True,\n                timeout=30\n            )\n        # Handle other frameworks...\n\n        if result.returncode == 0:\n            return f\"All tests passed!\\n{result.stdout}\"\n        else:\n            return f\"Tests failed:\\n{result.stdout}\\n{result.stderr}\"\n\n    except subprocess.TimeoutExpired:\n        return \"Tests timed out after 30 seconds\"\n    except FileNotFoundError:\n        return f\"{test_framework} not found. Please install it first.\"\n    except Exception as e:\n        return f\"Error running tests: {e}\"\n</code></pre>"},{"location":"api/slash-commands/#built-in-commands","title":"Built-in Commands","text":"<p>Bespoken may include some built-in commands:</p> <ul> <li><code>/help</code> - Show available commands</li> <li><code>/exit</code> or <code>/quit</code> - Exit the chat session</li> <li><code>/clear</code> - Clear the screen</li> <li><code>/debug</code> - Toggle debug mode</li> </ul> <p>These can be overridden by providing your own implementations.</p>"},{"location":"api/slash-commands/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Clear Names: Use descriptive command names that indicate the action    <pre><code># Good\n\"/save-chat\", \"/set-model\", \"/run-tests\"\n\n# Less clear\n\"/s\", \"/m\", \"/t\"\n</code></pre></p> </li> <li> <p>Help Text: Always include docstrings    <pre><code>def my_command():\n    \"\"\"Brief description of what this command does\"\"\"\n    # Implementation\n</code></pre></p> </li> <li> <p>User Feedback: Always return a message indicating what happened    <pre><code>def good_command():\n    # Do something\n    return \"Successfully completed the action!\"\n\ndef bad_command():\n    # Do something\n    # No return - user won't know if it worked\n</code></pre></p> </li> <li> <p>Error Handling: Handle errors gracefully    <pre><code>def safe_command():\n    try:\n        # Risky operation\n        result = perform_operation()\n        return f\"Success: {result}\"\n    except SpecificError as e:\n        return f\"Operation failed: {e}\"\n    except Exception as e:\n        return f\"Unexpected error: {e}\"\n</code></pre></p> </li> <li> <p>Confirm Destructive Actions: Use <code>ui.confirm()</code> for dangerous operations    <pre><code>def delete_files():\n    if ui.confirm(\"Delete all temporary files?\", default=False):\n        # Perform deletion\n        return \"Files deleted\"\n    return \"Deletion cancelled\"\n</code></pre></p> </li> </ol>"},{"location":"api/slash-commands/#example-complete-chat-with-commands","title":"Example: Complete Chat with Commands","text":"<pre><code>from bespoken import chat, ui\nfrom bespoken.tools import FileTool, TodoTools\n\ndef set_role():\n    \"\"\"Change assistant personality\"\"\"\n    roles = [\"helpful\", \"concise\", \"detailed\", \"creative\"]\n    role = ui.choice(\"Select communication style:\", roles)\n    return f\"I'll be {role} in my responses.\"\n\ndef show_stats():\n    \"\"\"Show session statistics\"\"\"\n    # In a real implementation, track these\n    return \"\"\"Session Statistics:\n- Messages: 42\n- Tools used: 7\n- Files edited: 3\n- Time elapsed: 15 minutes\"\"\"\n\ndef take_break():\n    \"\"\"Remind to take a break\"\"\"\n    minutes = ui.input(\"Remind me in how many minutes? \")\n    return f\"I'll remind you to take a break in {minutes} minutes. Keep coding!\"\n\n# Create a comprehensive chat interface\nchat(\n    model_name=\"anthropic/claude-3-5-sonnet-20240620\",\n    tools=[FileTool(\"main.py\"), TodoTools()],\n    system_prompt=\"You are a helpful coding assistant.\",\n    slash_commands={\n        \"/role\": set_role,\n        \"/stats\": show_stats,\n        \"/break\": take_break,\n    }\n)\n</code></pre> <p>When the user types <code>/role</code>, they'll be prompted to choose a communication style, and the assistant will adjust accordingly.</p>"},{"location":"api/tools/","title":"Tools API Reference","text":"<p>This page documents all the tools available in <code>bespoken.tools</code>.</p>"},{"location":"api/tools/#filesystem","title":"FileSystem","text":"<p>A comprehensive file system operations toolbox that can work with multiple files and directories.</p> <pre><code>from bespoken.tools import FileSystem\n\n# Initialize the file system tool\nfs = FileSystem(working_directory=\".\")\n\n# Available methods:\n# - list_files(directory) - List files and directories\n# - read_file(file_path) - Read content from a file\n# - write_file(file_path, content) - Write content to a file\n# - replace_in_file(file_path, old_string, new_string) - Replace text with diff preview\n</code></pre> <p>Key Features: - Works with absolute or relative paths - Shows diffs before applying changes - Requires user confirmation for replacements - Handles file encoding properly - Truncates large files (&gt;50KB) when reading</p>"},{"location":"api/tools/#filetool","title":"FileTool","text":"<p>A single-file editing tool that constrains operations to one specific file.</p> <pre><code>from bespoken.tools import FileTool\n\n# Create a tool for editing a specific file\ntool = FileTool(\"path/to/file.py\")\n\n# Or let the user choose interactively\ntool = FileTool()  # Prompts for file path\n\n# Available methods:\n# - get_file_path() - Returns the file this tool can access\n# - read_file() - Read the file's content\n# - replace_in_file(old_string, new_string) - Replace text with diff preview\n</code></pre> <p>Key Features: - Locked to a single file for safety - Shows colored diffs with line numbers - Requires user confirmation for changes - Cannot access other files</p>"},{"location":"api/tools/#todotools","title":"TodoTools","text":"<p>A simple todo list manager for tracking tasks during your session.</p> <pre><code>from bespoken.tools import TodoTools\n\n# Initialize the todo tool\ntodos = TodoTools()\n\n# Available methods:\n# - add_todo(task) - Add a new todo item\n# - list_todos() - List all todos with status\n# - mark_todo_done(index) - Mark a todo as completed (1-based index)\n# - flush_todos() - Clear all todos\n</code></pre> <p>Example Usage: <pre><code>todos.add_todo(\"Implement new feature\")\ntodos.add_todo(\"Write tests\")\ntodos.list_todos()  # Shows: 1. [\u25cb] Implement new feature, 2. [\u25cb] Write tests\ntodos.mark_todo_done(1)\ntodos.list_todos()  # Shows: 1. [\u2713] Implement new feature, 2. [\u25cb] Write tests\n</code></pre></p>"},{"location":"api/tools/#webfetchtool","title":"WebFetchTool","text":"<p>Fetches web content and converts it to markdown for easy processing.</p> <pre><code>from bespoken.tools import WebFetchTool\n\n# Initialize with optional timeout\nweb = WebFetchTool(timeout=30)\n\n# Fetch and convert a webpage to markdown\ncontent = web.fetch_url(\"https://example.com\")\n</code></pre> <p>Key Features: - Converts HTML to clean markdown - Removes scripts and styles - Handles errors gracefully - Configurable timeout</p>"},{"location":"api/tools/#playwrighttool","title":"PlaywrightTool","text":"<p>Browser automation tool for dynamic web interaction (requires <code>bespoken[browser]</code> extra).</p> <pre><code>from bespoken.tools import PlaywrightTool\n\n# Initialize browser tool\nbrowser = PlaywrightTool(headless=False, browser_type=\"chromium\")\n\n# Available methods:\n# - navigate(url) - Go to a URL\n# - click_text(text) - Click element containing text\n# - fill_field(label_or_placeholder, text) - Fill input field\n# - screenshot(path) - Take a screenshot\n# - get_page_content() - Get current page HTML\n# - extract_text() - Extract visible text\n# - wait_for_text(text, timeout) - Wait for text to appear\n# - close() - Close the browser\n</code></pre> <p>Installation: <pre><code>pip install bespoken[browser]\n# or\nuv pip install \"bespoken[browser]\"\n</code></pre></p>"},{"location":"api/tools/#command-execution-tools","title":"Command Execution Tools","text":""},{"location":"api/tools/#run_command","title":"run_command","text":"<p>A standalone function for executing shell commands with confirmation.</p> <pre><code>from bespoken.tools.command import run_command\n\n# Execute any shell command\noutput = run_command(\"ls -la\", working_directory=\"/tmp\", timeout=30)\n</code></pre> <p>Features: - Requires user confirmation before execution - Configurable timeout - Captures stdout/stderr and exit codes - Shows command details before execution</p>"},{"location":"api/tools/#gittool","title":"GitTool","text":"<p>Safe git operations with built-in confirmations.</p> <pre><code>from bespoken.tools.command import GitTool\n\n# Initialize git tool\ngit = GitTool(auto_trust=False)\n\n# Available methods:\n# - status(working_directory) - Get git status\n# - log(args, working_directory) - Get git log\n# - diff(args, working_directory) - Get git diff\n# - branch(args, working_directory) - List branches\n</code></pre> <p>Example: <pre><code>git.status()  # Shows current git status\ngit.log(\"--oneline -5\")  # Last 5 commits\ngit.diff(\"--staged\")  # Show staged changes\n</code></pre></p>"},{"location":"api/tools/#npmtool","title":"NpmTool","text":"<p>Safe npm operations for Node.js projects.</p> <pre><code>from bespoken.tools.command import NpmTool\n\n# Initialize npm tool\nnpm = NpmTool(auto_trust=False)\n\n# Available methods:\n# - list(depth, working_directory) - List packages\n# - outdated(working_directory) - Check outdated packages\n# - audit(fix, working_directory) - Security audit\n# - scripts(working_directory) - List npm scripts\n</code></pre>"},{"location":"api/tools/#pythontool","title":"PythonTool","text":"<p>Python and pip operations with optional UV support.</p> <pre><code>from bespoken.tools.command import PythonTool\n\n# Initialize with UV support (default)\npython = PythonTool(auto_trust=False, uv=True)\n\n# Available methods:\n# - version() - Get Python version\n# - pip_list(format, working_directory) - List packages\n# - pip_show(package, working_directory) - Show package details\n# - check_import(module, working_directory) - Test imports\n</code></pre>"},{"location":"api/tools/#trust-system","title":"Trust System","text":"<p>Command tools support an auto-trust feature to skip confirmations:</p> <pre><code># Trust the tool to skip confirmations\ngit = GitTool(auto_trust=True)\n\n# Or trust it later via UI\nfrom bespoken import ui\nui.trust_tool(\"GitTool\")\n</code></pre>"},{"location":"api/tools/#debug-output","title":"Debug Output","text":"<p>All tools provide debug output when enabled:</p> <pre><code>from bespoken import chat\n\nchat(\n    tools=[FileSystem()],\n    debug=True  # Enable debug output\n)\n</code></pre> <p>This shows: - What the LLM is calling - Tool status messages - What the tool returns to the LLM</p>"},{"location":"api/ui/","title":"UI Components API Reference","text":"<p>This page documents all the UI components available in <code>bespoken.ui</code>.</p>"},{"location":"api/ui/#core-display-functions","title":"Core Display Functions","text":""},{"location":"api/ui/#print","title":"print","text":"<pre><code>from bespoken.ui import print\n\n# Print text with consistent left padding\nprint(\"Hello, world!\")\nprint(\"Multi-line\\ntext\\nis properly padded\", indent=4)\n</code></pre>"},{"location":"api/ui/#print_empty_line","title":"print_empty_line","text":"<pre><code>from bespoken.ui import print_empty_line\n\n# Print an empty line with padding (maintains visual consistency)\nprint_empty_line()\nprint_empty_line(indent=4)\n</code></pre>"},{"location":"api/ui/#print_neutral","title":"print_neutral","text":"<pre><code>from bespoken.ui import print_neutral\n\n# Print text in neutral gray color with wrapping\nprint_neutral(\"This is some neutral information that will wrap properly.\")\n</code></pre>"},{"location":"api/ui/#tool-status-messages","title":"Tool Status Messages","text":"<p>These functions are used by tools to provide feedback:</p>"},{"location":"api/ui/#tool_status","title":"tool_status","text":"<pre><code>from bespoken.ui import tool_status\n\n# Print a cyan status message with extra whitespace\ntool_status(\"Preparing to execute command...\")\n</code></pre>"},{"location":"api/ui/#tool_debug","title":"tool_debug","text":"<pre><code>from bespoken.ui import tool_debug\n\n# Print debug info in magenta (only when DEBUG_MODE is True)\ntool_debug(\"&gt;&gt;&gt; LLM calling tool: read_file()\")\n</code></pre>"},{"location":"api/ui/#tool_error","title":"tool_error","text":"<pre><code>from bespoken.ui import tool_error\n\n# Print error message in red\ntool_error(\"Failed to connect to server\")\n</code></pre>"},{"location":"api/ui/#tool_success","title":"tool_success","text":"<pre><code>from bespoken.ui import tool_success\n\n# Print success message in green\ntool_success(\"Operation completed successfully\")\n</code></pre>"},{"location":"api/ui/#tool_warning","title":"tool_warning","text":"<pre><code>from bespoken.ui import tool_warning\n\n# Print warning message in yellow\ntool_warning(\"This action may take a while...\")\n</code></pre>"},{"location":"api/ui/#user-input-functions","title":"User Input Functions","text":""},{"location":"api/ui/#input","title":"input","text":"<pre><code>from bespoken.ui import input\n\n# Get basic input with padding\nname = input(\"Enter your name: \")\n\n# With auto-completion\nlanguages = [\"python\", \"javascript\", \"rust\", \"go\"]\nlang = input(\"Choose language: \", completions=languages)\n</code></pre> <p>Features: - File path auto-completion with <code>@</code> prefix - Command history with up/down arrows - Auto-suggestions from history - Custom completions support</p>"},{"location":"api/ui/#confirm","title":"confirm","text":"<pre><code>from bespoken.ui import confirm\n\n# Ask for yes/no confirmation\nif confirm(\"Continue with operation?\"):\n    # proceed\n    pass\n\n# With custom default\nconfirm(\"Delete file?\", default=False)\n</code></pre>"},{"location":"api/ui/#choice","title":"choice","text":"<pre><code>from bespoken.ui import choice\n\n# Present multiple choice selection\noption = choice(\"Select an option:\", [\"Option A\", \"Option B\", \"Option C\"])\n\n# Supports keyboard shortcuts (numbers)\nrole = choice(\"What role should I take?\", [\"pirate\", \"teacher\", \"professor\"])\n</code></pre>"},{"location":"api/ui/#streaming-output","title":"Streaming Output","text":"<p>For displaying LLM responses with proper word wrapping:</p>"},{"location":"api/ui/#stream","title":"stream","text":"<pre><code>from bespoken.ui import stream\n\n# Stream chunks of text with word-aware wrapping\nchunks = [\"Hello \", \"world! \", \"This is a long sentence that will wrap properly.\"]\nstream(chunks)\n</code></pre>"},{"location":"api/ui/#start_streaming-stream_chunk-end_streaming","title":"start_streaming / stream_chunk / end_streaming","text":"<pre><code>from bespoken.ui import start_streaming, stream_chunk, end_streaming\n\n# For manual streaming control\nstart_streaming()\nstream_chunk(\"First chunk \")\nstream_chunk(\"with more text\")\nend_streaming()\n</code></pre>"},{"location":"api/ui/#banner-and-customization","title":"Banner and Customization","text":""},{"location":"api/ui/#show_banner","title":"show_banner","text":"<pre><code>from bespoken.ui import show_banner\n\n# Display the default bespoken ASCII art banner\nshow_banner()\n</code></pre>"},{"location":"api/ui/#set_ascii_art","title":"set_ascii_art","text":"<pre><code>from bespoken.ui import set_ascii_art\n\n# Customize the banner\ncustom_art = \"\"\"\n  _____ _    _ ____ _______ ____  __  __ \n / ____| |  | / ___|__   __/ __ \\|  \\/  |\n| |    | |  | \\___ \\  | | | |  | | \\  / |\n| |    | |  | |___) | | | | |  | | |\\/| |\n| |____| |__| |____/  | | | |__| | |  | |\n \\_____|____/ |_____| |_|  \\____/|_|  |_|\n\"\"\"\n\nset_ascii_art(custom_art, subtitle=\"My Custom Tool v1.0\")\nshow_banner()\n</code></pre>"},{"location":"api/ui/#tool-trust-system","title":"Tool Trust System","text":"<p>Manage which tools require confirmation:</p>"},{"location":"api/ui/#trust_tool-untrust_tool-is_tool_trusted","title":"trust_tool / untrust_tool / is_tool_trusted","text":"<pre><code>from bespoken.ui import trust_tool, untrust_tool, is_tool_trusted\n\n# Trust a tool (no confirmation needed)\ntrust_tool(\"GitTool\")\n\n# Check if trusted\nif is_tool_trusted(\"GitTool\"):\n    print(\"Git operations won't ask for confirmation\")\n\n# Remove trust\nuntrust_tool(\"GitTool\")\n</code></pre>"},{"location":"api/ui/#confirm_tool_action","title":"confirm_tool_action","text":"<pre><code>from bespoken.ui import confirm_tool_action\n\n# Used internally by tools to request confirmation\nif confirm_tool_action(\n    \"GitTool\",\n    \"Execute: git commit -m 'Fix bug'\",\n    {\"Working directory\": \"/home/user/project\"}\n):\n    # Execute the action\n    pass\n</code></pre>"},{"location":"api/ui/#global-configuration","title":"Global Configuration","text":""},{"location":"api/ui/#padding-constants","title":"Padding Constants","text":"<pre><code>from bespoken.ui import LEFT_PADDING, RIGHT_PADDING\n\n# Default padding values\n# LEFT_PADDING = 2\n# RIGHT_PADDING = 2\n</code></pre> <p>These values control the consistent indentation throughout the UI.</p>"},{"location":"api/ui/#console-access","title":"Console Access","text":"<p>For advanced usage, you can access the Rich console:</p> <pre><code>from bespoken.ui import _console\n\n# Direct console access (use sparingly)\n_console.rule(\"Section Break\")\n</code></pre>"},{"location":"api/ui/#example-building-a-custom-tool-with-ui","title":"Example: Building a Custom Tool with UI","text":"<pre><code>from bespoken.ui import tool_status, tool_success, tool_error, confirm\nimport llm\n\nclass CustomTool(llm.Toolbox):\n    \"\"\"Example tool using UI components.\"\"\"\n\n    def process_data(self, data: str) -&gt; str:\n        tool_status(f\"Processing {len(data)} characters...\")\n\n        if not confirm(\"This will modify data. Continue?\"):\n            tool_error(\"Operation cancelled by user\")\n            return \"Cancelled\"\n\n        # Process the data...\n        result = data.upper()\n\n        tool_success(f\"Processed successfully!\")\n        return result\n</code></pre>"},{"location":"api/ui/#best-practices","title":"Best Practices","text":"<ol> <li>Consistency: Always use the UI functions instead of raw print() for consistent padding</li> <li>Colors: Use status functions appropriately (error=red, success=green, etc.)</li> <li>Confirmations: Use confirm() for destructive or important operations</li> <li>Streaming: Use the streaming functions for LLM output to ensure proper word wrapping</li> <li>Trust: Only trust tools that are safe to run without confirmation</li> </ol>"},{"location":"concepts/overview/","title":"Overview","text":"<p>Bespoken is built on several core concepts that work together to provide a powerful LLM-powered CLI experience:</p>"},{"location":"concepts/overview/#key-concepts","title":"Key Concepts","text":""},{"location":"concepts/overview/#1-llm-interaction","title":"1. LLM Interaction","text":"<p>Bespoken uses the llm library from Simon Willison to interact with various LLM providers. This gives you access to models from Anthropic, OpenAI, and others, including local models.</p>"},{"location":"concepts/overview/#2-tool-system","title":"2. Tool System","text":"<p>The tool system allows you to define specific capabilities that the LLM can access, constraining its actions to only what you explicitly permit.</p>"},{"location":"concepts/overview/#3-slash-commands","title":"3. Slash Commands","text":"<p>Slash commands provide user-triggered actions that can be executed during a conversation, enhancing the interactive experience.</p>"},{"location":"concepts/overview/#4-ui-components","title":"4. UI Components","text":"<p>Bespoken includes a set of UI components that make the CLI experience more interactive and user-friendly.</p>"},{"location":"concepts/overview/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  User Interface \u2502\u2500\u2500\u2500\u2500&gt;\u2502  Bespoken    \u2502\u2500\u2500\u2500\u2500&gt;\u2502  LLM Integration  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u2502\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502   Tools    \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>This architecture allows Bespoken to be both powerful and extensible while maintaining a simple interface for users.</p>"},{"location":"guides/quick-start/","title":"Quickstart","text":""},{"location":"guides/quick-start/#quickstart","title":"Quickstart","text":"<p>This is the simplest quickstart for an agent that can only make changes to a Python file.</p> app.py<pre><code>from bespoken import chat\nfrom bespoken.tools import FileTool\nfrom bespoken import ui\n\ndef set_role():\n    \"\"\"Set a voice for the assistant\"\"\"\n    roles = [\"pirate\", \"teacher\", \"professor\"]\n    role = ui.choice(\"What role should I take?\", roles)\n    return f\"You are now speaking like a {role}. Please respond in character for this role.\"\n\nchat(\n    model_name=\"anthropic/claude-3-5-sonnet-20240620\",\n    tools=[FileTool(\"edit.py\")],\n    system_prompt=\"You are a helpful assistant.\",\n    debug=False,\n    slash_commands={\n        \"/role\": set_role,\n    }\n)\n</code></pre>"}]}